<div align="center">
  
![MySQL CDC](https://img.icons8.com/color/96/mysql-logo.png)
![Apache Kafka](https://img.icons8.com/?size=96&id=fOhLNqGJsUbJ&format=png)

# Pipeline Completo de Change Data Capture com Zero Duplicatas

**Atualizado: 14 de Janeiro de 2026**

[![Follow @nicoleepaixao](https://img.shields.io/github/followers/nicoleepaixao?label=Follow&style=social)](https://github.com/nicoleepaixao)
[![Star this repo](https://img.shields.io/github/stars/nicoleepaixao/mysql-cdc-kafka-debezium?style=social)](https://github.com/nicoleepaixao/mysql-cdc-kafka-debezium)
[![Medium Article](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://nicoleepaixao.medium.com/replica√ß√£o-cdc-de-mysql-para-mysql-usando-kafka-debezium-da-frustra√ß√£o-√†-solu√ß√£o-de6d2fb2a3eb)

<p align="center">
  <a href="README-PT.md">üáßüá∑</a>
  <a href="README.md">üá∫üá∏</a>
</p>

</div>

---

<p align="center">
  <img src="img/mysql-cdc-kafka-debezium.png" alt="CDC Architecture" width="1200">
</p>

## **Vis√£o Geral**

Este projeto implementa um pipeline automatizado de Change Data Capture (CDC) para replica√ß√£o MySQL usando Kafka e Debezium. A solu√ß√£o aborda um desafio cr√≠tico: garantir que a replica√ß√£o CDC capture apenas novos registros ap√≥s a restaura√ß√£o de backup do banco de dados sem duplicar dados existentes. Toda a configura√ß√£o roda localmente via Docker Compose, permitindo valida√ß√£o e testes r√°pidos de configura√ß√µes CDC.

---

## **O Problema**

Ao restaurar um banco de dados MySQL de um backup, a replica√ß√£o CDC deve:

| **Requisito** | **Desafio** |
|-----------------|---------------|
| **Capturar apenas novos registros** | Evitar reprocessamento de dados hist√≥ricos j√° no backup |
| **Prevenir duplicatas** | Garantir que o destino n√£o receba inser√ß√µes duplicadas |
| **Sincronizar do ponto de backup** | Iniciar CDC do timestamp exato do backup |
| **Validar automaticamente** | Valida√ß√£o manual √© demorada e propensa a erros |

### **Cen√°rio do Mundo Real**

```text
Backup do Banco de Dados de Produ√ß√£o (3 registros) ‚Üí Restaurar no Destino
    ‚Üì
Novas transa√ß√µes ocorrem (2 registros)
    ‚Üì
CDC deve capturar APENAS esses 2 novos registros
    ‚Üì
Destino deve ter: 3 (backup) + 2 (novos) = 5 registros total
```

### **Por Que Isso Importa**

‚úÖ **Integridade de Dados**: Previne registros duplicados no banco de dados de destino  
‚úÖ **Efici√™ncia de Recursos**: Evita processamento e armazenamento desnecess√°rios de dados  
‚úÖ **Confian√ßa Operacional**: Valida√ß√£o automatizada reduz erro humano  
‚úÖ **Velocidade de Desenvolvimento**: Testes locais permitem itera√ß√£o r√°pida  
‚úÖ **Prontid√£o para Produ√ß√£o**: Valida comportamento CDC antes do deployment em produ√ß√£o

---

## **Como Funciona**

### **Fluxo de Valida√ß√£o**

O projeto automatiza um cen√°rio completo de valida√ß√£o CDC:

| **Est√°gio** | **Registros Origem** | **Registros Destino** | **Status** |
|-----------|-------------------|-------------------|------------|
| **1. Estado Inicial** | 3 | 3 | Ambos bancos id√™nticos (p√≥s-backup) |
| **2. Inser√ß√£o de Backlog** | 5 | 3 | 2 novos registros apenas na origem |
| **3. Ativa√ß√£o CDC** | 5 | 5 | Conectores replicam registros faltantes |
| **4. Teste Tempo Real** | 6 | 6 | Nova inser√ß√£o propaga imediatamente |

### **Componentes Principais**

| **Componente** | **Prop√≥sito** | **Configura√ß√£o** |
|---------------|-------------|-------------------|
| **MySQL Origem** | Banco similar √† produ√ß√£o com binlog | Porta 3307, binlog_format=ROW |
| **MySQL Destino** | Simula destino de backup restaurado | Porta 3308, config padr√£o |
| **Apache Kafka** | Plataforma de streaming de eventos | Broker √∫nico, auto-cria√ß√£o de t√≥picos |
| **Zookeeper** | Coordena√ß√£o do cluster Kafka | Requerido para Kafka 2.x |
| **Debezium Source** | Captura mudan√ßas do binlog MySQL | Modo snapshot: initial |
| **Debezium Sink** | Escreve mudan√ßas no banco de destino | Modo insert: upsert |

### **Estrat√©gia de Captura CDC**

```text
Comportamento do Conector Debezium Source:
‚îú‚îÄ‚îÄ snapshot.mode: initial
‚îÇ   ‚îú‚îÄ‚îÄ Faz snapshot inicial dos dados existentes
‚îÇ   ‚îú‚îÄ‚îÄ Publica snapshot no t√≥pico Kafka
‚îÇ   ‚îî‚îÄ‚îÄ Depois muda para streaming binlog
‚îú‚îÄ‚îÄ Rastreamento de Posi√ß√£o do Binlog
‚îÇ   ‚îú‚îÄ‚îÄ Armazena posi√ß√£o no t√≥pico Kafka
‚îÇ   ‚îú‚îÄ‚îÄ Retoma da √∫ltima posi√ß√£o ao reiniciar
‚îÇ   ‚îî‚îÄ‚îÄ Garante entrega exactly-once
‚îî‚îÄ‚îÄ Evolu√ß√£o de Schema
    ‚îú‚îÄ‚îÄ Captura mudan√ßas DDL
    ‚îú‚îÄ‚îÄ Armazena em t√≥pico de hist√≥rico de schema
    ‚îî‚îÄ‚îÄ Permite sink adaptar automaticamente
```

---

## **Estrutura do Projeto**

```text
mysql-cdc-kafka-debezium/
‚îÇ
‚îú‚îÄ‚îÄ README.md                          # Documenta√ß√£o completa
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml                 # Orquestra√ß√£o da infraestrutura
‚îÇ   ‚îú‚îÄ‚îÄ mysql-source (3307)
‚îÇ   ‚îú‚îÄ‚îÄ mysql-target (3308)
‚îÇ   ‚îú‚îÄ‚îÄ zookeeper (2181)
‚îÇ   ‚îú‚îÄ‚îÄ kafka (9092)
‚îÇ   ‚îî‚îÄ‚îÄ kafka-connect (8083)
‚îÇ
‚îú‚îÄ‚îÄ connect-plugins/                   # Depend√™ncias do conector
‚îÇ   ‚îî‚îÄ‚îÄ mysql-connector-j-8.0.33.jar  # Driver JDBC para sink
‚îÇ
‚îú‚îÄ‚îÄ dumps/                            # Volume compartilhado para backups
‚îÇ
‚îî‚îÄ‚îÄ scripts/                          # Scripts de automa√ß√£o
    ‚îú‚îÄ‚îÄ 01-setup-databases.sh         # Criar tabelas e usu√°rios
    ‚îú‚îÄ‚îÄ 02-insert-initial-data.sh     # Inserir 3 registros base
    ‚îú‚îÄ‚îÄ 03-insert-backlog.sh          # Inserir 2 registros adicionais
    ‚îú‚îÄ‚îÄ 04-create-source-connector.sh # Configurar Debezium source
    ‚îú‚îÄ‚îÄ 05-create-sink-connector.sh   # Configurar Debezium sink
    ‚îî‚îÄ‚îÄ 06-validate-sync.sh           # Verificar contagens de registros
```

---

## **In√≠cio R√°pido**

### **Pr√©-requisitos**

| **Requisito** | **Vers√£o** | **Prop√≥sito** |
|-----------------|-------------|-------------|
| Docker | 20.10+ | Runtime de container |
| Docker Compose | 2.0+ | Orquestra√ß√£o multi-container |
| curl | Qualquer | Intera√ß√£o com API REST |
| 8GB RAM | M√≠nimo | Executar todos os servi√ßos localmente |

### **1. Clonar Reposit√≥rio**

```bash
git clone https://github.com/nicoleepaixao/mysql-cdc-kafka-debezium.git
cd mysql-cdc-kafka-debezium
```

### **2. Baixar Driver JDBC (Opcional)**

```bash
mkdir -p connect-plugins
curl -L -o connect-plugins/mysql-connector-j-8.0.33.jar \
  https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/8.0.33/mysql-connector-j-8.0.33.jar
```

**Nota:** Necess√°rio apenas para testes com Confluent JDBC Sink. Debezium JDBC Sink tem driver embutido.

### **3. Iniciar Infraestrutura**

```bash
# Iniciar todos os servi√ßos
docker-compose up -d

# Verificar sa√∫de dos servi√ßos (aguardar ~30 segundos)
docker-compose ps

# Sa√≠da esperada: Todos os servi√ßos "Up" ou "healthy"
```

### **4. Configurar Bancos de Dados e Permiss√µes**

```bash
# Criar tabela origem
docker exec -it mysql-source mysql -uroot -prootpass1234 -e "
CREATE TABLE source.nicole_paixao (
  id INT AUTO_INCREMENT PRIMARY KEY,
  seller_id INT NOT NULL,
  score DECIMAL(10,2) NOT NULL,
  score_date DATE NOT NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);
"

# Criar tabela destino
docker exec -it mysql-target mysql -uroot -ptargetroot1234 -e "
CREATE TABLE targetdb.nicole_paixao (
  id INT AUTO_INCREMENT PRIMARY KEY,
  seller_id INT NOT NULL,
  score DECIMAL(10,2) NOT NULL,
  score_date DATE NOT NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);
"

# Conceder permiss√µes CDC (origem)
docker exec -it mysql-source mysql -uroot -prootpass1234 -e "
GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT 
ON *.* TO 'read_user'@'%';
FLUSH PRIVILEGES;
"

# Conceder permiss√µes de escrita (destino)
docker exec -it mysql-target mysql -uroot -ptargetroot1234 -e "
GRANT ALL PRIVILEGES ON targetdb.* TO 'dbadmin'@'%';
FLUSH PRIVILEGES;
"
```

### **5. Inserir Dataset Inicial**

```bash
# Inserir 3 registros na origem (simula dados de produ√ß√£o)
docker exec -it mysql-source mysql -uroot -prootpass1234 -e "
INSERT INTO source.nicole_paixao (seller_id, score, score_date)
VALUES
  (11111, 80.50, '2025-01-01'),
  (22222, 90.00, '2025-01-02'),
  (33333, 75.25, '2025-01-03');
"

# Inserir mesmos 3 registros no destino (simula restaura√ß√£o de backup)
docker exec -it mysql-target mysql -uroot -ptargetroot1234 -e "
INSERT INTO targetdb.nicole_paixao (seller_id, score, score_date)
VALUES
  (11111, 80.50, '2025-01-01'),
  (22222, 90.00, '2025-01-02'),
  (33333, 75.25, '2025-01-03');
"

# Verificar estado inicial
docker exec -it mysql-source mysql -uroot -prootpass1234 -e "
SELECT COUNT(*) AS source_count FROM source.nicole_paixao;"

docker exec -it mysql-target mysql -uroot -ptargetroot1234 -e "
SELECT COUNT(*) AS target_count FROM targetdb.nicole_paixao;"
```

**Resultado esperado:** Ambos bancos t√™m 3 registros ‚úÖ

### **6. Criar Backlog (Novas Transa√ß√µes)**

```bash
# Inserir 2 registros adicionais APENAS na origem
docker exec -it mysql-source mysql -uroot -prootpass1234 -e "
INSERT INTO source.nicole_paixao (seller_id, score, score_date)
VALUES
  (44444, 88.80, '2025-02-01'),
  (55555, 77.77, '2025-02-02');
"

# Verificar estado pr√©-CDC
docker exec -it mysql-source mysql -uroot -prootpass1234 -e "
SELECT COUNT(*) AS source_count FROM source.nicole_paixao;"
# Sa√≠da: 5 registros

docker exec -it mysql-target mysql -uroot -ptargetroot1234 -e "
SELECT COUNT(*) AS target_count FROM targetdb.nicole_paixao;"
# Sa√≠da: 3 registros (inalterado)
```

**Estado esperado:** Origem = 5, Destino = 3 ‚úÖ

### **7. Ativar Conector CDC Source**

```bash
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "mysql-source-nicole-paixao-v3",
    "config": {
      "connector.class": "io.debezium.connector.mysql.MySqlConnector",
      "database.hostname": "mysql-source",
      "database.port": "3306",
      "database.user": "read_user",
      "database.password": "readpass1234",
      "database.server.id": "888",
      "topic.prefix": "localtest",
      "database.include.list": "source",
      "table.include.list": "source.nicole_paixao",
      "snapshot.mode": "initial",
      "include.schema.changes": "false",
      "database.allowPublicKeyRetrieval": "true",
      "schema.history.internal.kafka.bootstrap.servers": "kafka:9092",
      "schema.history.internal.kafka.topic": "schema-changes.nicole_paixao_v3",
      "key.converter": "org.apache.kafka.connect.json.JsonConverter",
      "key.converter.schemas.enable": "true",
      "value.converter": "org.apache.kafka.connect.json.JsonConverter",
      "value.converter.schemas.enable": "true"
    }
  }'

# Verificar status do conector
curl http://localhost:8083/connectors/mysql-source-nicole-paixao-v3/status | jq
```

**Sa√≠da esperada:** `"state": "RUNNING"` ‚úÖ

### **8. Ativar Conector CDC Sink**

```bash
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "jdbc-sink-nicole-paixao",
    "config": {
      "connector.class": "io.debezium.connector.jdbc.JdbcSinkConnector",
      "tasks.max": "1",
      "topics": "localtest.source.nicole_paixao",
      "connection.url": "jdbc:mysql://mysql-target:3306/targetdb?useSSL=false&allowPublicKeyRetrieval=true",
      "connection.username": "dbadmin",
      "connection.password": "targetpass1234",
      "database.type": "mysql",
      "insert.mode": "upsert",
      "delete.enabled": "true",
      "primary.key.mode": "record_key",
      "primary.key.fields": "id",
      "schema.evolution": "basic",
      "table.name.format": "nicole_paixao"
    }
  }'

# Verificar status do conector
curl http://localhost:8083/connectors/jdbc-sink-nicole-paixao/status | jq
```

**Sa√≠da esperada:** `"state": "RUNNING"` ‚úÖ

### **9. Validar Sincroniza√ß√£o**

```bash
# Aguardar 5-10 segundos para processamento CDC
sleep 10

# Verificar contagem de registros no destino
docker exec -it mysql-target mysql -uroot -ptargetroot1234 -e "
SELECT COUNT(*) AS total_records FROM targetdb.nicole_paixao;
"
# Esperado: 5 registros

# Ver todos os registros para verificar aus√™ncia de duplicatas
docker exec -it mysql-target mysql -uroot -ptargetroot1234 -e "
SELECT id, seller_id, score, score_date 
FROM targetdb.nicole_paixao 
ORDER BY id;
"
```

**Resultado esperado:** 5 registros √∫nicos (3 iniciais + 2 backlog), sem duplicatas ‚úÖ

### **10. Testar Replica√ß√£o em Tempo Real**

```bash
# Inserir novo registro na origem
docker exec -it mysql-source mysql -uroot -prootpass1234 -e "
INSERT INTO source.nicole_paixao (seller_id, score, score_date)
VALUES (66666, 99.99, '2025-03-10');
"

# Verificar propaga√ß√£o imediata (aguardar 2-3 segundos)
sleep 3

docker exec -it mysql-target mysql -uroot -ptargetroot1234 -e "
SELECT COUNT(*) AS total_records FROM targetdb.nicole_paixao;
"
# Esperado: 6 registros

# Ver √∫ltimo registro
docker exec -it mysql-target mysql -uroot -ptargetroot1234 -e "
SELECT * FROM targetdb.nicole_paixao WHERE seller_id = 66666;
"
```

**Resultado esperado:** Novo registro aparece no destino em segundos ‚úÖ

---

## **Entendendo os Resultados**

### **Linha do Tempo de Valida√ß√£o**

| **Est√°gio** | **Contagem Origem** | **Contagem Destino** | **Delta** | **Status** |
|-----------|-----------------|-----------------|-----------|------------|
| Setup inicial | 3 | 3 | 0 | ‚ö†Ô∏è Baseline pr√©-sync |
| Ap√≥s inser√ß√£o backlog | 5 | 3 | 2 | ‚ö†Ô∏è Replica√ß√£o necess√°ria |
| Ap√≥s ativa√ß√£o CDC | 5 | 5 | 0 | ‚úÖ Sincronizado |
| Ap√≥s inser√ß√£o tempo real | 6 | 6 | 0 | ‚úÖ Streaming ativo |

### **Dados Esperados no Destino**

```sql
-- Resultados da consulta ap√≥s sincroniza√ß√£o CDC
mysql> SELECT * FROM targetdb.nicole_paixao ORDER BY id;
+----+-----------+-------+------------+---------------------+---------------------+
| id | seller_id | score | score_date | created_at          | updated_at          |
+----+-----------+-------+------------+---------------------+---------------------+
|  1 |     11111 | 80.50 | 2025-01-01 | 2025-01-02 10:00:00 | 2025-01-02 10:00:00 |
|  2 |     22222 | 90.00 | 2025-01-02 | 2025-01-02 10:00:00 | 2025-01-02 10:00:00 |
|  3 |     33333 | 75.25 | 2025-01-03 | 2025-01-02 10:00:00 | 2025-01-02 10:00:00 |
|  4 |     44444 | 88.80 | 2025-02-01 | 2025-01-02 10:05:00 | 2025-01-02 10:05:00 |
|  5 |     55555 | 77.77 | 2025-02-02 | 2025-01-02 10:05:00 | 2025-01-02 10:05:00 |
+----+-----------+-------+------------+---------------------+---------------------+
5 rows in set (0.00 sec)
```

### **Checklist de Verifica√ß√£o**

- ‚úÖ Sem registros duplicados (verificar unicidade de `id`)
- ‚úÖ Todos os 5 registros presentes (3 iniciais + 2 backlog)
- ‚úÖ Timestamps preservados corretamente
- ‚úÖ Chaves prim√°rias sequenciais (1-5)
- ‚úÖ Valores de dados coincidem exatamente com origem

---

## **Problemas Comuns e Solu√ß√µes**

### **Problema 1: T√≥pico de Hist√≥rico de Schema Faltando**

**Sintomas:**
```text
ERROR: The db history topic is missing. 
You may attempt to recover it by reconfiguring the connector...
```

**Causa Raiz:** T√≥pico de hist√≥rico de schema foi deletado ou ficou inconsistente entre rein√≠cios do conector.

**Solu√ß√£o:**
```bash
# Deletar conector antigo
curl -X DELETE http://localhost:8083/connectors/mysql-source-nicole-paixao-v3

# Usar novo nome de t√≥pico de hist√≥rico de schema
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "mysql-source-nicole-paixao-v4",
    "config": {
      "schema.history.internal.kafka.topic": "schema-changes.nicole_paixao_v4",
      ...
    }
  }'
```

### **Problema 2: Erros de Convers√£o de Data**

**Sintomas:**
```text
ERROR: Data truncation: Incorrect date value: '20091' for column 'score_date'
```

**Causa Raiz:** Confluent JDBC Sink n√£o lida com o tipo l√≥gico `io.debezium.time.Date` do Debezium.

**Solu√ß√£o:** Use Debezium JDBC Sink ao inv√©s de Confluent:
```json
{
  "connector.class": "io.debezium.connector.jdbc.JdbcSinkConnector",
  "database.type": "mysql"
}
```

**Compara√ß√£o de Conectores:**

| **Aspecto** | **Confluent JDBC Sink** | **Debezium JDBC Sink** |
|------------|------------------------|----------------------|
| Classe | `io.confluent.connect.jdbc.JdbcSinkConnector` | `io.debezium.connector.jdbc.JdbcSinkConnector` |
| Propriedade username | `connection.user` | `connection.username` |
| Tipo de banco | Auto-detectado | `database.type` necess√°rio |
| Tipos Debezium | ‚ùå Suporte limitado | ‚úÖ Suporte completo |
| Convers√£o DATE | ‚ùå Falha | ‚úÖ Converte corretamente |
| Convers√£o TIMESTAMP | ‚ùå Pode falhar | ‚úÖ Funciona nativamente |
| Melhor para | Fontes JDBC gen√©ricas | Fontes CDC Debezium |

### **Problema 3: Erro de Configura√ß√£o do Conector**

**Sintomas:**
```text
ERROR: Error configuring JdbcSinkConnectorConfig
```

**Causa Raiz:** Propriedades obrigat√≥rias faltando ou nomes de propriedades incorretos.

**Solu√ß√£o:** Certifique-se de que todas as propriedades obrigat√≥rias est√£o presentes:
```json
{
  "connector.class": "io.debezium.connector.jdbc.JdbcSinkConnector",
  "database.type": "mysql",
  "connection.username": "dbadmin",  // N√ÉO connection.user
  "connection.password": "targetpass1234",
  "insert.mode": "upsert",
  "primary.key.mode": "record_key",
  "primary.key.fields": "id"
}
```

### **Problema 4: Registros Duplicados Aparecendo**

**Sintomas:** Banco de dados de destino tem mais registros que o esperado, com valores duplicados.

**Causa Raiz:** Conector sink n√£o configurado para modo upsert corretamente ou configura√ß√£o de chave prim√°ria faltando.

**Solu√ß√£o:**
```json
{
  "insert.mode": "upsert",              // Habilita update em conflito
  "primary.key.mode": "record_key",     // Usa chave da mensagem Kafka
  "primary.key.fields": "id",           // Especifica coluna de conflito
  "delete.enabled": "true"              // Lida com eventos DELETE
}
```

### **Problema 5: API Kafka Connect N√£o Respondendo**

**Sintomas:**
```bash
curl: (7) Failed to connect to localhost port 8083: Connection refused
```

**Causa Raiz:** Kafka Connect n√£o iniciou completamente ou travou.

**Solu√ß√£o:**
```bash
# Verificar status do servi√ßo
docker-compose ps kafka-connect

# Ver logs
docker-compose logs -f kafka-connect

# Reiniciar se necess√°rio
docker-compose restart kafka-connect

# Aguardar API ficar pronta (~30 segundos)
curl http://localhost:8083/ | jq
```

---

## **Comandos √öteis**

### **Gerenciamento de Conectores**

```bash
# Listar todos os conectores
curl http://localhost:8083/connectors | jq

# Obter status de conector espec√≠fico
curl http://localhost:8083/connectors/mysql-source-nicole-paixao-v3/status | jq

# Obter configura√ß√£o do conector
curl http://localhost:8083/connectors/mysql-source-nicole-paixao-v3 | jq

# Deletar conector
curl -X DELETE http://localhost:8083/connectors/mysql-source-nicole-paixao-v3

# Reiniciar conector
curl -X POST http://localhost:8083/connectors/mysql-source-nicole-paixao-v3/restart

# Pausar conector
curl -X PUT http://localhost:8083/connectors/mysql-source-nicole-paixao-v3/pause

# Resumir conector
curl -X PUT http://localhost:8083/connectors/mysql-source-nicole-paixao-v3/resume
```

### **Gerenciamento de T√≥picos Kafka**

```bash
# Listar todos os t√≥picos
docker exec -it kafka kafka-topics \
  --bootstrap-server kafka:9092 \
  --list

# Descrever t√≥pico espec√≠fico
docker exec -it kafka kafka-topics \
  --bootstrap-server kafka:9092 \
  --describe \
  --topic localtest.source.nicole_paixao

# Consumir mensagens do in√≠cio
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server kafka:9092 \
  --topic localtest.source.nicole_paixao \
  --from-beginning

# Consumir com chave e timestamp
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server kafka:9092 \
  --topic localtest.source.nicole_paixao \
  --property print.key=true \
  --property print.timestamp=true \
  --from-beginning

# Deletar t√≥pico (requer limpeza)
docker exec -it kafka kafka-topics \
  --bootstrap-server kafka:9092 \
  --delete \
  --topic localtest.source.nicole_paixao
```

### **Opera√ß√µes de Banco de Dados MySQL**

```bash
# Conectar ao banco de dados origem
docker exec -it mysql-source mysql -uroot -prootpass1234 source

# Conectar ao banco de dados destino
docker exec -it mysql-target mysql -uroot -ptargetroot1234 targetdb

# Verificar status do binlog (origem)
docker exec -it mysql-source mysql -uroot -prootpass1234 -e "SHOW BINARY LOGS;"

# Ver posi√ß√£o do binlog (origem)
docker exec -it mysql-source mysql -uroot -prootpass1234 -e "SHOW MASTER STATUS;"

# Contar registros em ambos bancos
docker exec -it mysql-source mysql -uroot -prootpass1234 -e "
SELECT 'ORIGEM' AS db, COUNT(*) AS registros FROM source.nicole_paixao;"

docker exec -it mysql-target mysql -uroot -ptargetroot1234 -e "
SELECT 'DESTINO' AS db, COUNT(*) AS registros FROM targetdb.nicole_paixao;"
```

### **Reset Completo do Ambiente**

```bash
# Parar todos os containers
docker-compose down

# Remover todos os volumes (AVISO: deleta todos os dados)
docker-compose down -v

# Remover plugins Kafka Connect (opcional)
rm -rf connect-plugins/*

# Reiniciar do zero
docker-compose up -d

# Aguardar servi√ßos ficarem prontos
sleep 30
docker-compose ps
```

### **Debugging e Monitoramento**

```bash
# Ver todos os logs de servi√ßos
docker-compose logs -f

# Ver logs de servi√ßo espec√≠fico
docker-compose logs -f kafka-connect
docker-compose logs -f mysql-source

# Verificar uso de recursos do container
docker stats

# Inspecionar tarefas do conector
curl http://localhost:8083/connectors/mysql-source-nicole-paixao-v3/tasks | jq

# Ver offsets do conector
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server kafka:9092 \
  --topic connect-offsets \
  --from-beginning
```

---

## **Mergulho Profundo na Configura√ß√£o**

### **Par√¢metros do Conector Debezium Source**

| **Par√¢metro** | **Valor** | **Prop√≥sito** |
|---------------|-----------|-------------|
| `snapshot.mode` | `initial` | Fazer snapshot completo depois streaming de mudan√ßas |
| `database.server.id` | `888` | ID √∫nico do servidor para replica√ß√£o binlog |
| `topic.prefix` | `localtest` | Prefixo de nomenclatura do t√≥pico Kafka |
| `include.schema.changes` | `false` | N√£o capturar mudan√ßas DDL |
| `key.converter` | `JsonConverter` | Formato JSON para chaves de mensagem |
| `value.converter` | `JsonConverter` | Formato JSON para valores de mensagem |
| `schemas.enable` | `true` | Incluir schema nas mensagens |

### **Par√¢metros do Conector Debezium Sink**

| **Par√¢metro** | **Valor** | **Prop√≥sito** |
|---------------|-----------|-------------|
| `insert.mode` | `upsert` | Update em conflito, insert se novo |
| `delete.enabled` | `true` | Processar eventos DELETE da origem |
| `primary.key.mode` | `record_key` | Usar chave da mensagem Kafka como PK |
| `schema.evolution` | `basic` | Permitir adi√ß√µes de coluna automaticamente |
| `table.name.format` | Customizado | Mapear t√≥pico para nome de tabela espec√≠fico |

### **Op√ß√µes de Modo Snapshot**

| **Modo** | **Comportamento** | **Caso de Uso** |
|----------|-------------|-------------|
| `initial` | Snapshot completo ‚Üí streaming binlog | Setup inicial |
| `initial_only` | Apenas snapshot, sem streaming | Migra√ß√£o √∫nica de dados |
| `never` | Apenas streaming binlog | Retomar de posi√ß√£o conhecida |
| `when_needed` | Snapshot se nenhuma posi√ß√£o salva | Recupera√ß√£o autom√°tica |
| `schema_only` | Capturar schema, pular dados | Apenas evolu√ß√£o de schema |

---

## **Funcionalidades**

| **Funcionalidade** | **Descri√ß√£o** |
|-------------|-----------------|
| **Zero Duplicatas** | Modo upsert previne inser√ß√µes duplicadas |
| **Valida√ß√£o Automatizada** | Scripts verificam contagens de registros em cada est√°gio |
| **Rastreamento de Posi√ß√£o Binlog** | Retoma da √∫ltima posi√ß√£o ao reiniciar |
| **Evolu√ß√£o de Schema** | Adapta automaticamente a mudan√ßas DDL |
| **Teste Local** | Pipeline CDC completo no Docker |
| **Replica√ß√£o Tempo Real** | Lat√™ncia sub-segundo para novos registros |
| **Toler√¢ncia a Falhas** | Kafka armazena eventos para replay |
| **Suporte Multi-Tabela** | F√°cil extens√£o para m√∫ltiplas tabelas |
| **Propaga√ß√£o de DELETE** | Lida corretamente com opera√ß√µes DELETE |
| **Rastreamento de UPDATE** | Captura opera√ß√µes UPDATE com antes/depois |

---

## **Tecnologias Utilizadas**

| **Tecnologia** | **Vers√£o** | **Prop√≥sito** |
|----------------|-------------|-------------|
| Docker | 20.10+ | Runtime de container |
| Docker Compose | 2.0+ | Orquestra√ß√£o multi-container |
| MySQL | 8.0 | Bancos de dados origem e destino |
| Apache Kafka | 2.13-3.4 | Plataforma de streaming de eventos |
| Debezium | 2.6 | Conectores Change Data Capture |
| Kafka Connect | 2.6 | Framework de runtime do conector |
| Zookeeper | 3.8 | Coordena√ß√£o do cluster Kafka |

---

## **Casos de Uso**

| **Caso de Uso** | **Aplica√ß√£o** |
|--------------|-----------------|
| **Migra√ß√£o de Banco de Dados** | Validar CDC antes do cutover de produ√ß√£o |
| **Restaura√ß√£o de Backup** | Garantir sem dados duplicados ap√≥s restaura√ß√£o |
| **Recupera√ß√£o de Desastres** | Testar cen√°rios de failover localmente |
| **Sincroniza√ß√£o Multi-Regi√£o** | Replicar dados atrav√©s de regi√µes |
| **Pipeline de Analytics** | Streaming de mudan√ßas de banco para data warehouse |
| **Trilha de Auditoria** | Capturar todas as modifica√ß√µes de banco de dados |
| **Integra√ß√£o de Microservi√ßos** | Compartilhar mudan√ßas de dados atrav√©s de servi√ßos |
| **Testes de Desenvolvimento** | Ambiente seguro para configura√ß√£o CDC |

---

## **Melhores Pr√°ticas de Seguran√ßa**

### **Considera√ß√µes de Produ√ß√£o**

| **Aspecto** | **Recomenda√ß√£o** |
|------------|-------------------|
| **Credenciais** | Usar AWS Secrets Manager ou HashiCorp Vault |
| **Rede** | Colocar Kafka em subnet privada com VPC peering |
| **Criptografia** | Habilitar SSL/TLS para conex√µes Kafka e MySQL |
| **Controle de Acesso** | Implementar RBAC para API Kafka Connect |
| **Monitoramento** | Configurar alarmes CloudWatch para lag e falhas |
| **Backup** | Configurar pol√≠ticas de reten√ß√£o de t√≥picos Kafka |

### **Permiss√µes de Usu√°rio MySQL**

**Permiss√µes m√≠nimas necess√°rias para CDC:**

```sql
-- Usu√°rio banco origem (CDC somente-leitura)
GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT 
ON *.* TO 'cdc_user'@'%';

-- Usu√°rio banco destino (acesso escrita)
GRANT INSERT, UPDATE, DELETE ON targetdb.* TO 'sink_user'@'%';
```

---

## **Monitoramento e Observabilidade**

### **M√©tricas Principais para Rastrear**

| **M√©trica** | **O Que Monitorar** | **Limite de Alerta** |
|------------|-------------------|-------------------|
| **Lag de Replica√ß√£o** | Tempo entre mudan√ßa origem e atualiza√ß√£o destino | > 5 segundos |
| **Status do Conector** | Estado RUNNING vs FAILED | Qualquer estado FAILED |
| **Tamanho do T√≥pico Kafka** | Backlog de mensagens no t√≥pico | > 10.000 mensagens |
| **Taxa de Erro** | Processamento de mensagem falhou | > 1% taxa de erro |
| **Throughput** | Mensagens por segundo | Quedas s√∫bitas |

### **Comandos de Health Check**

```bash
# Verificar sa√∫de do conector
curl http://localhost:8083/connectors/mysql-source-nicole-paixao-v3/status | \
  jq '.connector.state, .tasks[].state'

# Monitorar lag do consumer Kafka
docker exec -it kafka kafka-consumer-groups \
  --bootstrap-server kafka:9092 \
  --describe \
  --group connect-jdbc-sink-nicole-paixao

# Ver erros recentes
docker-compose logs --tail=50 kafka-connect | grep ERROR
```

---

## **Ajuste de Performance**

### **Estrat√©gias de Otimiza√ß√£o**

| **Componente** | **Configura√ß√£o** | **Impacto** |
|---------------|------------------|-----------|
| **Conector Source** | `max.batch.size: 2048` | Batches maiores, menos requisi√ß√µes |
| **T√≥pico Kafka** | `partitions: 3` | Processamento paralelo |
| **Conector Sink** | `tasks.max: 3` | M√∫ltiplos writers |
| **Processamento em Batch** | `batch.size: 1000` | Reduz overhead de insert |
| **Rede** | Habilitar compress√£o | Reduz uso de banda |

### **Configura√ß√£o Otimizada Exemplo**

```json
{
  "name": "mysql-source-optimized",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "max.batch.size": "2048",
    "max.queue.size": "8192",
    "poll.interval.ms": "100",
    "tasks.max": "1"
  }
}
```

---

## **Guia de Troubleshooting**

### **Problema: Conector Preso em Estado PAUSED**

```bash
# Resumir o conector
curl -X PUT http://localhost:8083/connectors/mysql-source-nicole-paixao-v3/resume

# Verificar mudan√ßa de estado
curl http://localhost:8083/connectors/mysql-source-nicole-paixao-v3/status
```

### **Problema: Mensagens N√£o Aparecem no Destino**

```bash
# 1. Verificar se conector source est√° produzindo mensagens
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server kafka:9092 \
  --topic localtest.source.nicole_paixao \
  --max-messages 5

# 2. Verificar logs do conector sink
docker-compose logs kafka-connect | grep -i error

# 3. Verificar conectividade do banco destino
docker exec -it mysql-target mysql -udbadmin -ptargetpass1234 -e "SELECT 1"
```

### **Problema: Registros Duplicados Ap√≥s Rein√≠cio**

**Causa:** Conector sink n√£o usando modo upsert corretamente.

**Solu√ß√£o:**
```bash
# Deletar e recriar sink com configura√ß√£o adequada
curl -X DELETE http://localhost:8083/connectors/jdbc-sink-nicole-paixao

# Recriar com modo upsert
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "jdbc-sink-nicole-paixao",
    "config": {
      "insert.mode": "upsert",
      "primary.key.mode": "record_key",
      "primary.key.fields": "id"
    }
  }'
```

---

## **Cen√°rios Avan√ßados**

### **Filtrar Colunas Espec√≠ficas**

```json
{
  "name": "mysql-source-filtered",
  "config": {
    "column.include.list": "source.nicole_paixao.id,source.nicole_paixao.seller_id,source.nicole_paixao.score"
  }
}
```

### **Lidar com Mudan√ßas de Schema**

```sql
-- Adicionar nova coluna √† tabela origem
ALTER TABLE source.nicole_paixao ADD COLUMN region VARCHAR(50);

-- Debezium automaticamente captura DDL e atualiza sink
-- Verificar no destino
DESCRIBE targetdb.nicole_paixao;
```

### **Replica√ß√£o Multi-Tabela**

```json
{
  "name": "mysql-source-multi-table",
  "config": {
    "table.include.list": "source.nicole_paixao,source.sales_data,source.inventory"
  }
}
```

---

## **Artigo Completo no Medium**

Para um mergulho profundo abrangente nos desafios enfrentados e como cada problema foi resolvido, leia a hist√≥ria completa:

**[Replica√ß√£o CDC de MySQL para MySQL usando Kafka + Debezium: da frustra√ß√£o √† solu√ß√£o](https://nicoleepaixao.medium.com/replica√ß√£o-cdc-de-mysql-para-mysql-usando-kafka-debezium-da-frustra√ß√£o-√†-solu√ß√£o-de6d2fb2a3eb)**

---

## **Recursos Adicionais**

### **Documenta√ß√£o Oficial**

- [Debezium MySQL Connector](https://debezium.io/documentation/reference/stable/connectors/mysql.html) - Refer√™ncia completa do conector
- [Debezium JDBC Sink](https://debezium.io/documentation/reference/stable/connectors/jdbc.html) - Guia do conector sink
- [Kafka Connect](https://kafka.apache.org/documentation/#connect) - Docs do framework Connect
- [MySQL Binlog](https://dev.mysql.com/doc/refman/8.0/en/binary-log.html) - Configura√ß√£o do log bin√°rio
- [Kafka Topic Configuration](https://kafka.apache.org/documentation/#topicconfigs) - Par√¢metros de ajuste de t√≥picos

### **Recursos da Comunidade**

- [Debezium Community](https://debezium.io/community/) - F√≥runs e chat
- [Kafka Users Mailing List](https://kafka.apache.org/contact) - Suporte da comunidade
- [Stack Overflow - Debezium Tag](https://stackoverflow.com/questions/tagged/debezium) - Q&A

---

## **Melhorias Futuras**

| **Funcionalidade** | **Descri√ß√£o** | **Status** |
|-------------|-----------------|------------|
| **Schema Registry** | Gerenciamento de schema Avro | Planejado |
| **Integra√ß√£o ksqlDB** | Capacidades de stream processing | Em Desenvolvimento |
| **Dashboard de Monitoramento** | Dashboards Grafana para m√©tricas | Planejado |
| **Multi-Datacenter** | Setup de replica√ß√£o cross-region | Futuro |
| **Automa√ß√£o Terraform** | Deployment Infrastructure as Code | Planejado |
| **Suporte AWS MSK** | Integra√ß√£o Kafka gerenciado | Futuro |
| **Filtragem de Change Data** | Filtros de replica√ß√£o n√≠vel de linha | Planejado |

---

## **Conecte-se & Siga**

Mantenha-se atualizado com melhores pr√°ticas CDC, streaming Kafka e engenharia de dados:

<div align="center">

[![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/nicoleepaixao)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?logo=linkedin&logoColor=white&style=for-the-badge)](https://www.linkedin.com/in/nicolepaixao/)
[![Medium](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@nicoleepaixao)

</div>

---

## **Aviso Legal**

Este projeto √© para prop√≥sitos educacionais e de teste. O setup Docker Compose √© projetado para ambientes de desenvolvimento local. Configura√ß√µes CDC, settings Kafka e par√¢metros de banco de dados podem precisar de ajuste para uso em produ√ß√£o. Sempre valide comportamento de replica√ß√£o em ambientes de staging antes de implantar em produ√ß√£o. Consulte documenta√ß√£o oficial do Debezium e Apache Kafka para melhores pr√°ticas de produ√ß√£o.

---

<div align="center">

**Replique seus dados com CDC com confian√ßa!**

*Documento Criado: 2 de Janeiro de 2026*

Made with ‚ù§Ô∏è by [Nicole Paix√£o](https://github.com/nicoleepaixao)

</div>
